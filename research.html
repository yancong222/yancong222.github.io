<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <link rel="stylesheet" href="stylesheet.css" />
  <title>Yan Cong</title>
  <meta name="description" content="*** Language Data Researcher ***">
  <style>
    body { display: flex; font-family: system-ui, -apple-system, 'Segoe UI', Roboto, 'Helvetica Neue', Arial; }
    #sidebar { width: 260px; padding: 20px; position: fixed; top: 0; left: 0; height: 100vh; overflow: auto; box-sizing: border-box; }
    #content { margin-left: 300px; padding: 28px; max-width: 900px; }
    details { margin-bottom: 30px; }
    summary { font-size: 1.1rem; cursor: pointer; outline: none; }
    ul { margin-left: 20px; }
    .keywords { font-style: italic; font-size: 0.92em; margin-bottom: 10px; }
    a { text-decoration: none; }
    a:hover { text-decoration: underline; }
    .back-to-top { display: inline-block; margin-top: 10px; }
  </style>
</head>
<body>

<div id="sidebar">
  <h3>Contents</h3>
  <ul>
    <li><a href="#section1">Natural language understanding</a></li>
    <li><a href="#section2">Computational approach to language function and disfunction</a></li>
    <li><a href="#section3">Description and experiments in linguistic meaning</a></li>
  </ul>
</div>

<div id="content">
<a id="top"></a>

<!-- SECTION 1 -->
<details open>
  <summary id="section1">Natural language understanding</summary>
  <div class="keywords">LLMs · semantics · implicature · surprisal · discourse connectives</div>
  <ul>
    <li style="list-style-type: square;"><strong>Cong, Y.</strong> (2024). Manner implicatures in large language models. <i>Nature Scientific Reports. </i> <a href="https://doi.org/10.1038/s41598-024-80571-3" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: square;"><strong>Cong, Y.</strong> and Rayz, R. (2025). Language models demonstrate the good-enough processing seen in humans. <i>In Proceedings of CogSci. </i> <a href="https://escholarship.org/uc/item/60v8d8sw" target="_blank">[PDF]</a>. <a href="https://github.com/yancong222/EschersLLMs/blob/main/PosterCogSci2025CongRayz.pdf" target="_blank">[Poster]</a></li>

    <li style="list-style-type: square;">Britton, J.R.; <strong>Cong, Y.</strong>; Hsu, Y-Y.; Chersoni, E.; and Blache, P. (2024). On the Influence of Discourse Connectives on the Predictions of Humans and Language Models. <i>Frontiers in Human Neuroscience. </i> <a href="https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2024.1363120/abstract" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: square;">Pranav, A.; <strong>Cong, Y.</strong>; Chersoni, E.; Hsu, Y-Y.; and Lenci, A. (2024). Comparing Static and Contextual Distributional Semantic Models on Intrinsic Tasks: An Evaluation on Mandarin Chinese Datasets. <i>Proceedings of LREC-COLING. </i> <a href="https://aclanthology.org/2024.lrec-main.320.pdf" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: square;"><strong>Cong, Y.</strong>; Chersoni, E.; Hsu, Y-Y.; and Blache, P. (2023). Investigating the Effect of Discourse Connectives on Transformer Surprisal: Language Models Understand Connectives, Even So They Are Surprised. <i>Proceedings of BlackboxNLP. </i> <a href="https://aclanthology.org/2023.blackboxnlp-1.17/" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: square;"><strong>Cong, Y.</strong>; Chersoni, E.; Hsu, Y-Y.; and Lenci, A. (2023). Are Language Models Sensitive to Semantic Attraction? A Study on Surprisal. <i>Proceedings of *SEM. </i> <a href="https://aclanthology.org/2023.starsem-1.13.pdf" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: square;"><strong>Cong, Y.</strong> (2022). Psycholinguistic Diagnosis of Language Models' Commonsense Reasoning. <i>Proceedings of CSRR. </i> <a href="http://dx.doi.org/10.18653/v1/2022.csrr-1.3" target="_blank">[PDF]</a>. <a href="https://doi.org/10.48448/39ye-c967" target="_blank">[VIDEO]</a>.</li>

    <li style="list-style-type: square;"><strong>Cong, Y.</strong> (2022). Pre-trained Language Models’ Interpretation of Evaluativity Implicature: Evidence from Gradable Adjectives Usage in Context. <i>Proceedings of UnImplicit.</i> <a href="https://aclanthology.org/2022.unimplicit-1.1/" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: square;">Pandia, L.; <strong>Cong, Y.</strong> and Ettinger, A. (2021). Pragmatic competence of pre-trained language models through the lens of discourse connectives. <i>Proceedings of CoNLL.</i> <a href="https://aclanthology.org/2021.conll-1.29.pdf" target="_blank">[PDF]</a>.</li>

  </ul>
</details>
<a class="back-to-top" href="#top">Back to top</a>


<!-- SECTION 2 -->
<details>
  <summary id="section2">Computational approach to language function and disfunction</summary>
  <div class="keywords">language learning · aphasia · schizophrenia · clinical NLP · speech disturbances</div>
  <ul>
    <li style="list-style-type: disc;"><strong>Cong, Y.</strong> (2025). Demystifying large language models in second language development research. <i>Computer Speech & Language. </i> <a href="https://doi.org/10.1016/j.csl.2024.101700" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: disc;"><strong>Cong, Y.</strong> (2024). Second language learning of degree expressions: A computational approach. <i>Cambridge Natural Language Processing. </i> <a href="https://doi.org/10.1017/nlp.2024.56" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: disc;"><strong>Cong, Y.</strong> (2024). AI Language Models: An Opportunity to Enhance Language Learning. <i>Informatics.</i> <a href="https://doi.org/10.3390/informatics11030049" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: disc;"><strong>Cong, Y.</strong> and Lee, J. (2025). Tracking priming-induced language recovery in aphasia with pre-trained language models. <i>Frontiers in Artificial Intelligence. </i> <a href="https://doi.org/10.3389/frai.2025.1668399" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: disc;"><strong>Cong, Y.</strong>; LaCroix, A.N.; Lee, J. (2024). Clinical efficacy of pre-trained large language models through the lens of aphasia. <i>Nature Scientific Reports. </i> <a href="https://doi.org/10.1038/s41598-024-66576-y" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: disc;"><strong>Cong, Y.</strong>; Lee, J.; LaCroix, A.N. (2024). Leveraging pre-trained large language models for aphasia detection in English and Chinese speakers. <i> Proceedings of Clinical NLP. </i> <a href="https://aclanthology.org/2024.clinicalnlp-1.20/" target="_blank">[PDF]</a>. <a href="https://doi.org/10.48448/5013-dn34" target="_blank">[VIDEO]</a>.</li>

    <li style="list-style-type: disc;">Cho, S.; <strong>Cong, Y.</strong>; Mehta, A.; Nikzad, AH.; Berretta, S.; Behbehani, L.; Liberman, M.Y.; Tang, X.S. (2025). Unique signatures in verbal fluency task performance in schizophrenia and depression. <i> Schizophrenia Research: Cognition. </i> <a href="https://doi.org/10.1016/j.scog.2025.100407" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: disc;">Tang, S.X.; <strong>Cong, Y.</strong>; Mercep, G..; Bhatti, M.; Serpe, G.; Gromova, V.; Berretta, S.; John, M.; Liberman, M.Y.; Sinvani, L. (2023). Characterizing and Detecting Delirium with Clinical and Computational measures of Speech and Language Disturbance. <i> Journal of Psychiatry and Neuroscience. </i> <a href="https://www.jpn.ca/content/48/4/E255" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: disc;">Tang, S.X.; H<span>&#228;</span>nsel, K.; <strong>Cong, Y.</strong>; Nikzad, AH.; Mehta, A.; Cho, S.; Berretta, S.; Behbehani, L.; Pradhan, S.; John, M. and Liberman, MY. (2022). Latent Factors of Language Disturbance and Relationships to Quantitative Speech Features. <i>Schizophrenia Bulletin. </i> <a href="https://doi.org/10.1093/schbul/sbac145" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: disc;">Tang, S.X.; <strong>Cong, Y.</strong>; Nikzad, AH.; Mehta, A.; Cho, S.; H<span>&#228;</span>nsel, K.; Berretta, S.; Dhar, A.; Kane, JM. and Malhotra, A. (2022). Clinical and Computational Speech Measures are Associated with Social Cognition in Schizophrenia Spectrum Disorders. <i>Schizophrenia research. </i> <a href="https://doi.org/10.1016/j.schres.2022.06.012" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: disc;">Nikzad, AH.; <strong>Cong, Y.</strong>; Berretta, S.; H<span>&#228;</span>nsel, K.; Cho, S.; Pradhan, S.; Behbehani, L.; DeSouza, D.; Liberman, MY. and Tang, S.X. (2022). Who Does What to Whom? Graph Representations of Action-Predication in Speech Relate to Psychopathological Dimensions of Psychosis. <i>Schizophrenia.</i> <a href="https://doi.org/10.1038/s41537-022-00263-7" target="_blank">[PDF]</a>.</li>

  </ul>
</details>
<a class="back-to-top" href="#top">Back to top</a>


<!-- SECTION 3 -->
<details>
  <summary id="section3">Description and experiments in linguistic meaning</summary>
  <div class="keywords">semantics · experiments · Mandarin · syntax · psycholinguistics</div>
  <ul>
    <li style="list-style-type: circle;"><strong>Cong, Y.</strong> (2022). Judge-Dependence in Quality Nouns: A Semantic Analysis of The Mandarin Chinese <i>you</i> NP Structure. <i>Asian Languages and Linguistics. </i> <a href="https://doi.org/10.1075/alal.21007.con" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: circle;"><strong>Cong, Y.</strong> (2021). Competition in Natural Language Meaning: The Case of Adjective Constructions in Mandarin Chinese and Beyond. <i>Doctoral dissertation, Michigan State University.</i> <a href="https://doi.org/10.25335/z1cs-7363" target="_blank">[PDF]</a> <a href="https://mediaspace.msu.edu/media/t/1_qfxndaa3" target="_blank">[Artificial language learning experiment - speaker perspective VIDEO]</a> <a href="https://mediaspace.msu.edu/media/t/1_ior9r1fx" target="_blank">[listener perspective VIDEO]</a> <a href="https://osf.io/b6dwe/" target="_blank">[Design document]</a>.</li>

    <li style="list-style-type: circle;"><strong>Cong, Y.</strong> and Buccola, B. (2021). Alternatives in non-scalar implicature: The case of Mandarin adjective constructions. Presentation at PLC. <a href="https://github.com/yancong222/yancong222.github.io/blob/master/flap_poster_cong_apr05.pdf" target="_blank"> [Poster]</a> <a href="https://www.researchgate.net/publication/351104248_Alternatives_in_non-scalar_implicature_The_case_of_Mandarin_adjective_constructions" target="_blank"> [Abstract]</a> <a href="https://github.com/yancong222/scripts/tree/main/PsychoPy3%20experiments" target="_blank"> [Truth-Value Judgment survey experiment script]</a>.</li>

    <li style="list-style-type: circle;"><strong>Cong, Y.</strong> and Ngonyani, D. (2022). A syntactic analysis of the cooccurrence of stative and passive in Kiswahili. <i>Proceedings of ACAL.</i> <a href="https://langsci-press.org/catalog/book/306" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: circle;">Smith, K.; Ma, Y.; <strong>Cong, Y.</strong> and Beretta, A. (2019). Semantic attraction in sentence processing. Presentation at CUNY. <a href="https://www.colorado.edu/event/cuny2019/sites/default/files/attached-files/b72_smith_etal.pdf" target="_blank">[Abstract]</a>.</li>

    <li style="list-style-type: circle;"><strong>Cong, Y.</strong> (2018). The Non-canonical argument realization of Chinese alternations. <i>Proceedings of NACCL.</i> <a href="https://www.researchgate.net/publication/341598112_The_Non-canonical_Argument_Realization_of_Chinese_Alternations" target="_blank">[PDF]</a>.</li>

    <li style="list-style-type: circle;">Parrish, A.; Kelley, P.; Smith, K.; <strong>Cong, Y.</strong> and Beretta, A. (2017). Prosodic lengthening and boundary prediction in nominal compounds: An ERP study. Presentation at SNL. <a href="https://www.researchgate.net/publication/341598361_Prosodic_Lengthening_and_Boundary_Prediction_in_Nominal_Compounds_An_ERP_study" target="_blank">[Poster]</a>.</li>

    <li style="list-style-type: circle;"><strong>Cong, Y.</strong>; Huang, C.-R.; and Wee, L.-H. (2015). The invertible construction in Chinese. <i>Proceedings of PACLIC.</i> <a href="https://aclanthology.org/Y15-1024.pdf" target="_blank">[PDF]</a>.</li>

  </ul>
</details>
<a class="back-to-top" href="#top">Back to top</a>

</div>
</body>
</html>
